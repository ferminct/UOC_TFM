{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "charitable-rally",
   "metadata": {},
   "source": [
    "### IIMPORTAR LIBRERIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "civic-dubai",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "supreme-continent",
   "metadata": {},
   "source": [
    "### CARGAR LIBRERIAS DESDE .CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "promotional-theta",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_base = \"C:\\\\Users\\\\fermi\\\\UOC\\\\Master UOC. Posgrado en inteligencia de negocio\\\\TFM\\\\Ficheros\"\n",
    "dataset_1 = pd.read_csv(path_base + \"\\diabetic_num.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "intimate-muslim",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71515, 45)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-kinase",
   "metadata": {},
   "source": [
    "### ESTABLECER VARIABLES DEPENDIENTES E INDEPENDIENTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "peaceful-ontario",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>race_num</th>\n",
       "      <th>gender_num</th>\n",
       "      <th>admission_type_id</th>\n",
       "      <th>discharge_disposition_id</th>\n",
       "      <th>admission_source_id</th>\n",
       "      <th>time_in_hospital</th>\n",
       "      <th>num_lab_procedures</th>\n",
       "      <th>num_procedures</th>\n",
       "      <th>num_medications</th>\n",
       "      <th>number_outpatient</th>\n",
       "      <th>...</th>\n",
       "      <th>glimepiride_num</th>\n",
       "      <th>glipizide_num</th>\n",
       "      <th>glyburide_num</th>\n",
       "      <th>pioglitazone_num</th>\n",
       "      <th>rosiglitazone_num</th>\n",
       "      <th>insulin_num</th>\n",
       "      <th>change_num</th>\n",
       "      <th>diabetesMed_num</th>\n",
       "      <th>age2_num</th>\n",
       "      <th>diag_1_3_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>77</td>\n",
       "      <td>6</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   race_num  gender_num  admission_type_id  discharge_disposition_id  \\\n",
       "0         3           1                  2                         1   \n",
       "1         3           1                  3                         1   \n",
       "2         3           1                  1                         3   \n",
       "\n",
       "   admission_source_id  time_in_hospital  num_lab_procedures  num_procedures  \\\n",
       "0                    1                 8                  77               6   \n",
       "1                    1                 2                  49               1   \n",
       "2                    7                 4                  68               2   \n",
       "\n",
       "   num_medications  number_outpatient  ...  glimepiride_num  glipizide_num  \\\n",
       "0               33                  0  ...                2              2   \n",
       "1               11                  0  ...                2              2   \n",
       "2               23                  0  ...                2              2   \n",
       "\n",
       "   glyburide_num  pioglitazone_num  rosiglitazone_num  insulin_num  \\\n",
       "0              1                 2                  2            3   \n",
       "1              2                 2                  2            2   \n",
       "2              2                 2                  2            2   \n",
       "\n",
       "   change_num  diabetesMed_num  age2_num  diag_1_3_num  \n",
       "0           1                2         2             1  \n",
       "1           2                1         2             6  \n",
       "2           2                2         3             5  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = dataset_1.iloc[:, np.r_[0:2, 3:18, 20,22,23, 25,26,33,39,40,42,43]]\n",
    "y = dataset_1.iloc[:,-1].values\n",
    "X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "growing-poetry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['race_num', 'gender_num', 'admission_type_id',\n",
       "       'discharge_disposition_id', 'admission_source_id', 'time_in_hospital',\n",
       "       'num_lab_procedures', 'num_procedures', 'num_medications',\n",
       "       'number_outpatient', 'number_emergency', 'number_inpatient',\n",
       "       'number_diagnoses', 'max_glu_serum_num', 'A1Cresult_num',\n",
       "       'metformin_num', 'repaglinide_num', 'glimepiride_num', 'glipizide_num',\n",
       "       'glyburide_num', 'pioglitazone_num', 'rosiglitazone_num', 'insulin_num',\n",
       "       'change_num', 'diabetesMed_num', 'age2_num', 'diag_1_3_num'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "distinguished-momentum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(71515, 27)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-wheat",
   "metadata": {},
   "source": [
    "### DATOS DE ENTRENAMIENTO Y DE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "surgical-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state =1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ruled-cooking",
   "metadata": {},
   "source": [
    "#### Datos test vs Datos train. Casos totales, Casos Positivos y Casos Negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "breathing-archive",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total registros del train 57212\n",
      "Total positivos en y_train:  5029\n",
      "Porcentaje de positivos:  8.79 %\n",
      "Total negativos en y_train:  52183\n",
      "Porcentaje de negativos 91.21 %\n"
     ]
    }
   ],
   "source": [
    "total = len(y_train)\n",
    "one_count = np.sum(y_train)\n",
    "one_count_pct=one_count/total\n",
    "zero_count = total - one_count\n",
    "zero_count_pct = 1 - one_count_pct\n",
    "\n",
    "print(\"Total registros del train\", total)\n",
    "print(\"Total positivos en y_train: \", one_count)\n",
    "print(\"Porcentaje de positivos: \", round(one_count_pct*100,2), \"%\")\n",
    "print(\"Total negativos en y_train: \", zero_count)\n",
    "print(\"Porcentaje de negativos\", round(zero_count_pct*100,2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "necessary-sight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total registros del test 14303\n",
      "Total positivos en y_test:  1264\n",
      "Porcentaje de positivos:  8.84 %\n",
      "Total negativos en y_test:  13039\n",
      "Porcentaje de negativos 91.16 %\n"
     ]
    }
   ],
   "source": [
    "total = len(y_test)\n",
    "one_count = np.sum(y_test)\n",
    "one_count_pct=one_count/total\n",
    "zero_count = total - one_count\n",
    "zero_count_pct = 1 - one_count_pct\n",
    "\n",
    "print(\"Total registros del test\", total)\n",
    "print(\"Total positivos en y_test: \", one_count)\n",
    "print(\"Porcentaje de positivos: \", round(one_count_pct*100,2), \"%\")\n",
    "print(\"Total negativos en y_test: \", zero_count)\n",
    "print(\"Porcentaje de negativos\", round(zero_count_pct*100,2), \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-bennett",
   "metadata": {},
   "source": [
    "#### ESTANDARIZACIÓN DE DATOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "suspended-norman",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-valuation",
   "metadata": {},
   "source": [
    "#### Agrega Capas de entrada y Primera Capa Oculta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "extraordinary-hands",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnclas = tf.keras.models.Sequential()\n",
    "rnclas.add(tf.keras.layers.Dense(units = 268, activation ='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-madrid",
   "metadata": {},
   "source": [
    "#### Agrega Segunda Capa Oculta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "amber-blowing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnclas.add(tf.keras.layers.Dense(units = 250, activation ='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "signal-exposure",
   "metadata": {},
   "source": [
    "#### Agregar Tercera Capa Oculta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "raised-given",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnclas.add(tf.keras.layers.Dense(units = 38, activation ='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enhanced-diversity",
   "metadata": {},
   "source": [
    "#### Agrega Capa de Salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "prescription-river",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnclas.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-turning",
   "metadata": {},
   "source": [
    "#### Compilar Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "mobile-venezuela",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnclas.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "senior-posting",
   "metadata": {},
   "source": [
    "#### Entrenar Red Neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "democratic-glasgow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1788/1788 [==============================] - 1s 833us/step - loss: 0.2990 - accuracy: 0.9097\n",
      "Epoch 2/100\n",
      "1788/1788 [==============================] - 1s 831us/step - loss: 0.2910 - accuracy: 0.9121\n",
      "Epoch 3/100\n",
      "1788/1788 [==============================] - 1s 813us/step - loss: 0.2895 - accuracy: 0.9121\n",
      "Epoch 4/100\n",
      "1788/1788 [==============================] - 1s 826us/step - loss: 0.2879 - accuracy: 0.9120\n",
      "Epoch 5/100\n",
      "1788/1788 [==============================] - 1s 815us/step - loss: 0.2875 - accuracy: 0.9121\n",
      "Epoch 6/100\n",
      "1788/1788 [==============================] - 1s 819us/step - loss: 0.2868 - accuracy: 0.9120\n",
      "Epoch 7/100\n",
      "1788/1788 [==============================] - 1s 818us/step - loss: 0.2862 - accuracy: 0.9122\n",
      "Epoch 8/100\n",
      "1788/1788 [==============================] - 2s 879us/step - loss: 0.2857 - accuracy: 0.9121\n",
      "Epoch 9/100\n",
      "1788/1788 [==============================] - 2s 875us/step - loss: 0.2849 - accuracy: 0.9120\n",
      "Epoch 10/100\n",
      "1788/1788 [==============================] - 2s 896us/step - loss: 0.2839 - accuracy: 0.9122\n",
      "Epoch 11/100\n",
      "1788/1788 [==============================] - 1s 839us/step - loss: 0.2831 - accuracy: 0.9122\n",
      "Epoch 12/100\n",
      "1788/1788 [==============================] - 2s 876us/step - loss: 0.2827 - accuracy: 0.9122\n",
      "Epoch 13/100\n",
      "1788/1788 [==============================] - 1s 825us/step - loss: 0.2819 - accuracy: 0.9123\n",
      "Epoch 14/100\n",
      "1788/1788 [==============================] - 2s 896us/step - loss: 0.2809 - accuracy: 0.9122\n",
      "Epoch 15/100\n",
      "1788/1788 [==============================] - 2s 979us/step - loss: 0.2798 - accuracy: 0.9123\n",
      "Epoch 16/100\n",
      "1788/1788 [==============================] - 2s 1ms/step - loss: 0.2791 - accuracy: 0.9121\n",
      "Epoch 17/100\n",
      "1788/1788 [==============================] - 2s 926us/step - loss: 0.2780 - accuracy: 0.9124\n",
      "Epoch 18/100\n",
      "1788/1788 [==============================] - 2s 1ms/step - loss: 0.2768 - accuracy: 0.9124\n",
      "Epoch 19/100\n",
      "1788/1788 [==============================] - 2s 1ms/step - loss: 0.2753 - accuracy: 0.9123\n",
      "Epoch 20/100\n",
      "1788/1788 [==============================] - 2s 1ms/step - loss: 0.2749 - accuracy: 0.9123\n",
      "Epoch 21/100\n",
      "1788/1788 [==============================] - 2s 853us/step - loss: 0.2730 - accuracy: 0.9125\n",
      "Epoch 22/100\n",
      "1788/1788 [==============================] - 1s 831us/step - loss: 0.2724 - accuracy: 0.9124\n",
      "Epoch 23/100\n",
      "1788/1788 [==============================] - 1s 828us/step - loss: 0.2710 - accuracy: 0.9125\n",
      "Epoch 24/100\n",
      "1788/1788 [==============================] - 1s 834us/step - loss: 0.2697 - accuracy: 0.9127\n",
      "Epoch 25/100\n",
      "1788/1788 [==============================] - 2s 842us/step - loss: 0.2686 - accuracy: 0.9127\n",
      "Epoch 26/100\n",
      "1788/1788 [==============================] - 1s 834us/step - loss: 0.2669 - accuracy: 0.9128\n",
      "Epoch 27/100\n",
      "1788/1788 [==============================] - 2s 1ms/step - loss: 0.2655 - accuracy: 0.9130\n",
      "Epoch 28/100\n",
      "1788/1788 [==============================] - 1s 835us/step - loss: 0.2651 - accuracy: 0.9132\n",
      "Epoch 29/100\n",
      "1788/1788 [==============================] - 1s 829us/step - loss: 0.2633 - accuracy: 0.9130\n",
      "Epoch 30/100\n",
      "1788/1788 [==============================] - 1s 820us/step - loss: 0.2616 - accuracy: 0.9131\n",
      "Epoch 31/100\n",
      "1788/1788 [==============================] - 2s 874us/step - loss: 0.2604 - accuracy: 0.9137\n",
      "Epoch 32/100\n",
      "1788/1788 [==============================] - 1s 835us/step - loss: 0.2595 - accuracy: 0.9135\n",
      "Epoch 33/100\n",
      "1788/1788 [==============================] - 1s 831us/step - loss: 0.2581 - accuracy: 0.9142\n",
      "Epoch 34/100\n",
      "1788/1788 [==============================] - 2s 888us/step - loss: 0.2571 - accuracy: 0.9138\n",
      "Epoch 35/100\n",
      "1788/1788 [==============================] - 1s 836us/step - loss: 0.2562 - accuracy: 0.9141\n",
      "Epoch 36/100\n",
      "1788/1788 [==============================] - 2s 841us/step - loss: 0.2548 - accuracy: 0.9144\n",
      "Epoch 37/100\n",
      "1788/1788 [==============================] - 2s 939us/step - loss: 0.2531 - accuracy: 0.9147\n",
      "Epoch 38/100\n",
      "1788/1788 [==============================] - 2s 966us/step - loss: 0.2527 - accuracy: 0.9150\n",
      "Epoch 39/100\n",
      "1788/1788 [==============================] - 2s 944us/step - loss: 0.2521 - accuracy: 0.9149\n",
      "Epoch 40/100\n",
      "1788/1788 [==============================] - 2s 954us/step - loss: 0.2503 - accuracy: 0.9148\n",
      "Epoch 41/100\n",
      "1788/1788 [==============================] - 2s 956us/step - loss: 0.2496 - accuracy: 0.9152\n",
      "Epoch 42/100\n",
      "1788/1788 [==============================] - 2s 958us/step - loss: 0.2490 - accuracy: 0.9156\n",
      "Epoch 43/100\n",
      "1788/1788 [==============================] - 2s 938us/step - loss: 0.2476 - accuracy: 0.9158\n",
      "Epoch 44/100\n",
      "1788/1788 [==============================] - 2s 1ms/step - loss: 0.2469 - accuracy: 0.9157\n",
      "Epoch 45/100\n",
      "1788/1788 [==============================] - 2s 1ms/step - loss: 0.2461 - accuracy: 0.9164\n",
      "Epoch 46/100\n",
      "1788/1788 [==============================] - 2s 884us/step - loss: 0.2453 - accuracy: 0.9155\n",
      "Epoch 47/100\n",
      "1788/1788 [==============================] - 2s 858us/step - loss: 0.2436 - accuracy: 0.9166\n",
      "Epoch 48/100\n",
      "1788/1788 [==============================] - 2s 873us/step - loss: 0.2445 - accuracy: 0.9164\n",
      "Epoch 49/100\n",
      "1788/1788 [==============================] - 2s 852us/step - loss: 0.2429 - accuracy: 0.9166\n",
      "Epoch 50/100\n",
      "1788/1788 [==============================] - 2s 854us/step - loss: 0.2417 - accuracy: 0.9165\n",
      "Epoch 51/100\n",
      "1788/1788 [==============================] - 2s 841us/step - loss: 0.2416 - accuracy: 0.9173\n",
      "Epoch 52/100\n",
      "1788/1788 [==============================] - 2s 861us/step - loss: 0.2401 - accuracy: 0.9171\n",
      "Epoch 53/100\n",
      "1788/1788 [==============================] - 1s 828us/step - loss: 0.2396 - accuracy: 0.9167\n",
      "Epoch 54/100\n",
      "1788/1788 [==============================] - 1s 815us/step - loss: 0.2383 - accuracy: 0.9178\n",
      "Epoch 55/100\n",
      "1788/1788 [==============================] - 1s 824us/step - loss: 0.2380 - accuracy: 0.9173\n",
      "Epoch 56/100\n",
      "1788/1788 [==============================] - 1s 816us/step - loss: 0.2374 - accuracy: 0.9182\n",
      "Epoch 57/100\n",
      "1788/1788 [==============================] - 1s 816us/step - loss: 0.2366 - accuracy: 0.9184\n",
      "Epoch 58/100\n",
      "1788/1788 [==============================] - 1s 817us/step - loss: 0.2365 - accuracy: 0.9183\n",
      "Epoch 59/100\n",
      "1788/1788 [==============================] - 1s 820us/step - loss: 0.2352 - accuracy: 0.9186\n",
      "Epoch 60/100\n",
      "1788/1788 [==============================] - 1s 816us/step - loss: 0.2339 - accuracy: 0.9188\n",
      "Epoch 61/100\n",
      "1788/1788 [==============================] - 1s 820us/step - loss: 0.2331 - accuracy: 0.9194\n",
      "Epoch 62/100\n",
      "1788/1788 [==============================] - 1s 831us/step - loss: 0.2336 - accuracy: 0.9189\n",
      "Epoch 63/100\n",
      "1788/1788 [==============================] - 1s 823us/step - loss: 0.2321 - accuracy: 0.9193\n",
      "Epoch 64/100\n",
      "1788/1788 [==============================] - 1s 817us/step - loss: 0.2325 - accuracy: 0.9183\n",
      "Epoch 65/100\n",
      "1788/1788 [==============================] - 1s 820us/step - loss: 0.2308 - accuracy: 0.9203\n",
      "Epoch 66/100\n",
      "1788/1788 [==============================] - 1s 828us/step - loss: 0.2304 - accuracy: 0.9193\n",
      "Epoch 67/100\n",
      "1788/1788 [==============================] - 1s 825us/step - loss: 0.2302 - accuracy: 0.9196\n",
      "Epoch 68/100\n",
      "1788/1788 [==============================] - 1s 820us/step - loss: 0.2293 - accuracy: 0.9201\n",
      "Epoch 69/100\n",
      "1788/1788 [==============================] - 1s 823us/step - loss: 0.2289 - accuracy: 0.9198\n",
      "Epoch 70/100\n",
      "1788/1788 [==============================] - 1s 823us/step - loss: 0.2286 - accuracy: 0.9198\n",
      "Epoch 71/100\n",
      "1788/1788 [==============================] - 1s 827us/step - loss: 0.2277 - accuracy: 0.9193\n",
      "Epoch 72/100\n",
      "1788/1788 [==============================] - 1s 829us/step - loss: 0.2272 - accuracy: 0.9200\n",
      "Epoch 73/100\n",
      "1788/1788 [==============================] - 1s 825us/step - loss: 0.2260 - accuracy: 0.9209\n",
      "Epoch 74/100\n",
      "1788/1788 [==============================] - 1s 819us/step - loss: 0.2262 - accuracy: 0.9205\n",
      "Epoch 75/100\n",
      "1788/1788 [==============================] - 1s 810us/step - loss: 0.2261 - accuracy: 0.9201\n",
      "Epoch 76/100\n",
      "1788/1788 [==============================] - 1s 820us/step - loss: 0.2249 - accuracy: 0.9205\n",
      "Epoch 77/100\n",
      "1788/1788 [==============================] - 1s 834us/step - loss: 0.2244 - accuracy: 0.9210\n",
      "Epoch 78/100\n",
      "1788/1788 [==============================] - 2s 958us/step - loss: 0.2243 - accuracy: 0.9205\n",
      "Epoch 79/100\n",
      "1788/1788 [==============================] - 2s 956us/step - loss: 0.2241 - accuracy: 0.9205\n",
      "Epoch 80/100\n",
      "1788/1788 [==============================] - 2s 931us/step - loss: 0.2229 - accuracy: 0.9212\n",
      "Epoch 81/100\n",
      "1788/1788 [==============================] - 2s 854us/step - loss: 0.2229 - accuracy: 0.9211\n",
      "Epoch 82/100\n",
      "1788/1788 [==============================] - 2s 892us/step - loss: 0.2221 - accuracy: 0.9207\n",
      "Epoch 83/100\n",
      "1788/1788 [==============================] - 2s 841us/step - loss: 0.2211 - accuracy: 0.9216\n",
      "Epoch 84/100\n",
      "1788/1788 [==============================] - 2s 981us/step - loss: 0.2203 - accuracy: 0.9221\n",
      "Epoch 85/100\n",
      "1788/1788 [==============================] - 2s 887us/step - loss: 0.2204 - accuracy: 0.9214\n",
      "Epoch 86/100\n",
      "1788/1788 [==============================] - 2s 876us/step - loss: 0.2198 - accuracy: 0.9220\n",
      "Epoch 87/100\n",
      "1788/1788 [==============================] - 1s 832us/step - loss: 0.2194 - accuracy: 0.9220\n",
      "Epoch 88/100\n",
      "1788/1788 [==============================] - 2s 855us/step - loss: 0.2194 - accuracy: 0.9218\n",
      "Epoch 89/100\n",
      "1788/1788 [==============================] - 2s 861us/step - loss: 0.2197 - accuracy: 0.9212\n",
      "Epoch 90/100\n",
      "1788/1788 [==============================] - 2s 858us/step - loss: 0.2183 - accuracy: 0.9221\n",
      "Epoch 91/100\n",
      "1788/1788 [==============================] - 2s 873us/step - loss: 0.2176 - accuracy: 0.9220\n",
      "Epoch 92/100\n",
      "1788/1788 [==============================] - 2s 885us/step - loss: 0.2183 - accuracy: 0.9216\n",
      "Epoch 93/100\n",
      "1788/1788 [==============================] - 2s 872us/step - loss: 0.2177 - accuracy: 0.9231\n",
      "Epoch 94/100\n",
      "1788/1788 [==============================] - 2s 886us/step - loss: 0.2172 - accuracy: 0.9225\n",
      "Epoch 95/100\n",
      "1788/1788 [==============================] - 2s 933us/step - loss: 0.2172 - accuracy: 0.9229\n",
      "Epoch 96/100\n",
      "1788/1788 [==============================] - 1s 808us/step - loss: 0.2158 - accuracy: 0.9230\n",
      "Epoch 97/100\n",
      "1788/1788 [==============================] - 1s 817us/step - loss: 0.2159 - accuracy: 0.9232\n",
      "Epoch 98/100\n",
      "1788/1788 [==============================] - 1s 805us/step - loss: 0.2150 - accuracy: 0.9230\n",
      "Epoch 99/100\n",
      "1788/1788 [==============================] - 2s 875us/step - loss: 0.2151 - accuracy: 0.9224\n",
      "Epoch 100/100\n",
      "1788/1788 [==============================] - 2s 849us/step - loss: 0.2148 - accuracy: 0.9234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ca016f11f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnclas.fit(X_train, y_train, epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organizational-general",
   "metadata": {},
   "source": [
    "### PREDICCIONES DE LA MUESTRA DE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "southern-quilt",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rnclas.predict(X_test)\n",
    "\n",
    "\n",
    "y_pred_2 = (y_pred>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "assigned-canyon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[False],\n",
       "       [False],\n",
       "       [False],\n",
       "       ...,\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afraid-weight",
   "metadata": {},
   "source": [
    "### MATRIZ DE CONFUSIÓN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "comfortable-nerve",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12681   358]\n",
      " [ 1191    73]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred_2)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "mexican-pressure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Casos = 14303\n",
      "Verdaderos Positivos: 73\n",
      "Verdaderos Negativos: 12681\n",
      "Falsos Positivos:  358\n",
      "Falsos Negativos:  1191\n",
      "Exactitud = 0.89\n",
      "Precisión = 0.17\n",
      "Sensitividad = 0.06\n",
      "Especificidad = 0.97\n"
     ]
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred_2)\n",
    "TP = cm[1][1]\n",
    "TN = cm[0][0]\n",
    "FN = cm[1][0]\n",
    "FP = cm[0][1]\n",
    "total_casos = TP + FP + TN + FN\n",
    "print(\"Total Casos =\", total_casos)\n",
    "print(\"Verdaderos Positivos:\", TP)\n",
    "print(\"Verdaderos Negativos:\", TN)\n",
    "print(\"Falsos Positivos: \", FP)\n",
    "print(\"Falsos Negativos: \", FN)\n",
    "exactitud = ((TP+TN) / (TP+FP+TN+FN))\n",
    "print(f\"Exactitud = {round(exactitud,2)}\")\n",
    "precision = (TP / (TP+FP))\n",
    "print(f\"Precisión = {round(precision,2)}\")\n",
    "sensitividad = (TP / (TP + FN))\n",
    "print(f\"Sensitividad = {round(sensitividad,2)}\")\n",
    "especificidad = (TN/(TN+FP))\n",
    "print(f\"Especificidad = {round(especificidad, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "underlying-hayes",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
